\coms The part about \toidx{Moore-Penrose-Inverse} is still missing\come

\chapter{Gradienten- und CG-Verfahren}

Wir betrachten eine Funktion $f:\rr^n\to \rr$, die genügend glatt ist. Was genau das heißt, werden wir später spezifizieren. Für diese wollen wir das \toidx{reduzierte Minimierungsproblem}
\[
\min_{x\in \rr^n}f(x)
\]
lösen. Dabei optimieren wir über den ganzen Raum $\rr^n$, es gibt also keine Nebenbedingungen.\par 
Wir nehmen immer an, dass es ein $x_0\in\rr^n$ gibt,so dass die \toidx{Niveaumenge}
\[
N_{f(x_0)} = \{x\in \rr^n\ssp f(x)\leq f(x_0)\}
\]
kompakt ist. Weil $f$ stetig ist, garantiert diese Annahme die Existenz eines \textit{globalen} Minimums.
\lec